{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval Lab WiSe 2024/2025: Baseline Retrieval System\n",
    "\n",
    "This Jupyter notebook serves as a baseline retrieval system that you can improve upon.\n",
    "We use subsets of the MS MARCO datasets to retrieve passages of web documents.\n",
    "We will show you how to create a software submission to TIRA from this notebook.\n",
    "\n",
    "An overview of all corpora that we use in the current course is available at [https://tira.io/datasets?query=ir-lab-wise-2024](https://tira.io/datasets?query=ir-lab-wise-2024). The dataset IDs for loading the datasets are:\n",
    "\n",
    "- `ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training`: A subsample of the TREC 2019/2020 Deep Learning tracks on the MS MARCO v1 passage dataset. Use this dataset to tune your system(s).\n",
    "- `ir-lab-wise-2024/subsampled-ms-marco-rag-20241202-training` (_work in progress_): A subsample of the TREC 2024 Retrieval-Augmented Generation track on the MS MARCO v2.1 passage dataset. Use this dataset to tune your system(s).\n",
    "- `ir-lab-wise-2024/ms-marco-rag-20241203-test` (work in progress): The test corpus that we have created together in the course, based on the MS MARCO v2.1 passage dataset. We will use this dataset as the test dataset, i.e., evaluation scores become available only after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries\n",
    "\n",
    "We will use [tira](https://tira.io/), an information retrieval shared task platform, and [ir_dataset](https://ir-datasets.com/) for loading the datasets. Subsequently, we will build a retrieval system with [PyTerrier](https://github.com/terrier-org/pyterrier), an open-source search engine framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to install the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tira>=0.0.139 in /usr/local/lib/python3.10/dist-packages (0.0.139)\n",
      "Requirement already satisfied: ir-datasets in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
      "Requirement already satisfied: python-terrier==0.10.0 in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (4.66.1)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (0.5.6)\n",
      "Requirement already satisfied: matchpy in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (0.5.5)\n",
      "Requirement already satisfied: chest in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (0.2.3)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (0.3.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (1.26.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (3.1.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (1.11.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (1.3.2)\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (1.6.1)\n",
      "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (3.2)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (10.1.0)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (0.14.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (1.3.2)\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (0.3.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (2.31.0)\n",
      "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (1.2.14)\n",
      "Requirement already satisfied: nptyping==1.4.4 in /usr/local/lib/python3.10/dist-packages (from python-terrier==0.10.0) (1.4.4)\n",
      "Requirement already satisfied: typish>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from nptyping==1.4.4->python-terrier==0.10.0) (1.9.3)\n",
      "Requirement already satisfied: docker==7.*,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from tira>=0.0.139) (7.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tira>=0.0.139) (23.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker==7.*,>=7.1.0->tira>=0.0.139) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier==0.10.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier==0.10.0) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier==0.10.0) (2023.11.17)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.2.3)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (2.6)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (4.12.2)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.2.5)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (2.3.2)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.1.6)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.2.2)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (3.2.3)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.1.12)\n",
      "Requirement already satisfied: lz4>=3.1.10 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (4.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (6.0.1)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets) (2.5)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /usr/local/lib/python3.10/dist-packages (from ir-measures>=0.3.1->python-terrier==0.10.0) (1.0.12)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trec-car-tools>=2.5.4->ir-datasets) (1.0.0)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.10/dist-packages (from chest->python-terrier==0.10.0) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->python-terrier==0.10.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->python-terrier==0.10.0) (2.1.3)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from matchpy->python-terrier==0.10.0) (2.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->python-terrier==0.10.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->python-terrier==0.10.0) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->python-terrier==0.10.0) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->python-terrier==0.10.0) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->python-terrier==0.10.0) (0.5.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->python-terrier==0.10.0) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install 'tira>=0.0.139' ir-datasets 'python-terrier==0.10.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-09 10:04:46--  https://files.webis.de/software/pyterrier-plugins/custom-terrier-token-processing-1.0-SNAPSHOT-jar-with-dependencies.jar\n",
      "Resolving files.webis.de (files.webis.de)... 141.54.132.200\n",
      "Connecting to files.webis.de (files.webis.de)|141.54.132.200|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 499865236 (477M) [application/java-archive]\n",
      "Saving to: ‘/root/.pyterrier/custom-terrier-token-processing-0.0.1.jar’\n",
      "\n",
      "/root/.pyterrier/cu 100%[===================>] 476.71M   107MB/s    in 4.5s    \n",
      "\n",
      "2024-12-09 10:04:51 (106 MB/s) - ‘/root/.pyterrier/custom-terrier-token-processing-0.0.1.jar’ saved [499865236/499865236]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://files.webis.de/software/pyterrier-plugins/custom-terrier-token-processing-1.0-SNAPSHOT-jar-with-dependencies.jar -O /root/.pyterrier/custom-terrier-token-processing-0.0.1.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.10 (built by craigm on 2024-08-22 17:33) and terrier-helper 0.0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init(boot_packages=['mam10eks:custom-terrier-token-processing:0.0.1'])\n",
    "    from jnius import autoclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an API client to interact with the TIRA platform (e.g., to load datasets and submit runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded\n",
    "from tira.rest_api_client import Client\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the dataset\n",
    "\n",
    "We load the dataset by its ir_datasets ID (as listed in the Readme). Just be sure to add the `irds:` prefix before the dataset ID to tell PyTerrier to load the data from ir_datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier import get_dataset\n",
    "\n",
    "pt_dataset = get_dataset('irds:ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ir_datasets, ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "import pyterrier as pt\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "\n",
    "training_dataset = 'ir-lab-jena-leipzig-wise-2023/training-20231104-training'\n",
    "validation_dataset = 'ir-lab-jena-leipzig-wise-2023/validation-20231104-training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_queries = pt.io.read_topics(ir_datasets.topics_file(training_dataset), format='trecxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build an index\n",
    "\n",
    "We will then create an index from the documents in the dataset we just loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:  38%|███▊      | 26075/68261 [00:07<00:08, 4820.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:05:19.487 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (6114613) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents: 100%|██████████| 68261/68261 [00:13<00:00, 5141.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:05:27.222 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer -- Indexed 1 empty documents\n"
     ]
    }
   ],
   "source": [
    "from pyterrier import IterDictIndexer\n",
    "\n",
    "indexer_porter = IterDictIndexer(\n",
    "    # Store the index in the `index` directory.\n",
    "    \"../data/index\",\n",
    "    meta={'docno': 50, 'text': 4096},\n",
    "    # If an index already exists there, then overwrite it.\n",
    "    overwrite=True,\n",
    "    stemmer='PorterStemmer'\n",
    ")\n",
    "index_porter = indexer_porter.index(pt_dataset.get_corpus_iter())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:  38%|███▊      | 25912/68261 [00:03<00:04, 9319.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:05:32.610 [ForkJoinPool-2-worker-3] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (6114613) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents: 100%|██████████| 68261/68261 [00:08<00:00, 7887.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:05:39.636 [ForkJoinPool-2-worker-3] WARN org.terrier.structures.indexing.Indexer -- Indexed 1 empty documents\n"
     ]
    }
   ],
   "source": [
    "indexer_none = IterDictIndexer(\n",
    "    \"../data/index_none\",\n",
    "    meta={'docno': 50, 'text': 4096},\n",
    "    overwrite=True,\n",
    "    stemmer = None\n",
    ")\n",
    "\n",
    "index_none= indexer_none.index(pt_dataset.get_corpus_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:  37%|███▋      | 25488/68261 [00:03<00:05, 7339.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:05:45.803 [ForkJoinPool-3-worker-3] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (6114613) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents: 100%|██████████| 68261/68261 [00:08<00:00, 7595.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:05:52.623 [ForkJoinPool-3-worker-3] WARN org.terrier.structures.indexing.Indexer -- Indexed 1 empty documents\n"
     ]
    }
   ],
   "source": [
    "indexer_Snowball = IterDictIndexer(\n",
    "    \"../data/index_Snowball\",\n",
    "    meta={'docno': 50, 'text': 4096},\n",
    "    overwrite=True,\n",
    "    stemmer = 'EnglishSnowballStemmer'\n",
    ")\n",
    "\n",
    "index_Snowball = indexer_Snowball.index(pt_dataset.get_corpus_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:  38%|███▊      | 25865/68261 [00:05<00:14, 3021.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:06:00.860 [ForkJoinPool-4-worker-3] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (6114613) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents: 100%|██████████| 68261/68261 [00:10<00:00, 6293.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:06:07.930 [ForkJoinPool-4-worker-3] WARN org.terrier.structures.indexing.Indexer -- Indexed 1 empty documents\n"
     ]
    }
   ],
   "source": [
    "indexer_LemurKrovetz = IterDictIndexer(\n",
    "    \"../data/index_LemurKrovetz\",\n",
    "    meta={'docno': 50, 'text': 4096},\n",
    "    overwrite=True,\n",
    "    stemmer = 'LemurKrovetzStemmer'\n",
    ")\n",
    "\n",
    "index_LemurKrovetz = indexer_LemurKrovetz.index(pt_dataset.get_corpus_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents:  38%|███▊      | 26169/68261 [00:37<00:52, 802.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:06:49.376 [ForkJoinPool-5-worker-3] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (6114613) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-wise-2024/subsampled-ms-marco-deep-learning-20241201-training documents: 100%|██████████| 68261/68261 [01:32<00:00, 737.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:07:46.082 [ForkJoinPool-5-worker-3] WARN org.terrier.structures.indexing.Indexer -- Indexed 1 empty documents\n"
     ]
    }
   ],
   "source": [
    "indexer_standfordLemmatizer = IterDictIndexer(\n",
    "    \"../data/index_standfordLemmatizer\",\n",
    "    meta={'docno': 50, 'text': 4096},\n",
    "    overwrite=True,\n",
    "    stemmer = 'StanfordLemmatizer'\n",
    ")\n",
    "\n",
    "index_standfordLemmatizer = indexer_standfordLemmatizer.index(pt_dataset.get_corpus_iter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Define the retrieval pipeline\n",
    "\n",
    "We will define a simple retrieval pipeline using just BM25 as a baseline. For details, refer to the PyTerrier [documentation](https://pyterrier.readthedocs.io) or [tutorial](https://github.com/terrier-org/ecir2021tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier import BatchRetrieve\n",
    "\n",
    "bm25_porter = BatchRetrieve(index_porter, wmodel=\"BM25\")\n",
    "bm25_none = BatchRetrieve(index_none, wmodel=\"BM25\")\n",
    "bm25_snowball = BatchRetrieve(indexer_Snowball, wmodel=\"BM25\")\n",
    "bm25_lemurkrovetz = BatchRetrieve(indexer_LemurKrovetz, wmodel=\"BM25\")\n",
    "bm25_standfordLemmatizer = BatchRetrieve(index_standfordLemmatizer, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ir_datasets, ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "def run_bm25_grid_search_run(index, output_dir, queries):\n",
    "    \"\"\"\n",
    "        defaults: http://terrier.org/docs/current/javadoc/org/terrier/matching/models/BM25.html\n",
    "        k_1 = 1.2d, k_3 = 8d, b = 0.75d\n",
    "        We do not tune parameter k_3, as this parameter only impacts queries with reduntant terms.\n",
    "    \"\"\"\n",
    "    for b in [0.7, 0.75, 0.8]:\n",
    "        for k_1 in [1.1, 1.2, 1.3]:\n",
    "            system = f'bm25-b={b}-k_1={k_1}'\n",
    "            configuration = {\"bm25.b\" : b, \"bm25.k_1\": k_1}\n",
    "            run_output_dir = output_dir + '/' + system\n",
    "            !rm -Rf {run_output_dir}\n",
    "            !mkdir -p {run_output_dir}\n",
    "            print(f'Run {system}')\n",
    "            BM25 = pt.BatchRetrieve(index, wmodel=\"BM25\", controls=configuration, verbose=True)\n",
    "            run = BM25(queries)\n",
    "            persist_and_normalize_run(run, system, run_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run bm25-b=0.7-k_1=1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 672/672 [00:29<00:00, 22.50q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/training/bm25-b=0.7-k_1=1.1\".\n",
      "Done. run file is stored under \"grid-search/training/bm25-b=0.7-k_1=1.1/run.txt\".\n",
      "Run bm25-b=0.7-k_1=1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 672/672 [00:28<00:00, 23.25q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/training/bm25-b=0.7-k_1=1.2\".\n",
      "Done. run file is stored under \"grid-search/training/bm25-b=0.7-k_1=1.2/run.txt\".\n",
      "Run bm25-b=0.7-k_1=1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 672/672 [00:29<00:00, 22.66q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/training/bm25-b=0.7-k_1=1.3\".\n",
      "Done. run file is stored under \"grid-search/training/bm25-b=0.7-k_1=1.3/run.txt\".\n",
      "Run bm25-b=0.75-k_1=1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 672/672 [00:29<00:00, 22.76q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/training/bm25-b=0.75-k_1=1.1\".\n",
      "Done. run file is stored under \"grid-search/training/bm25-b=0.75-k_1=1.1/run.txt\".\n",
      "Run bm25-b=0.75-k_1=1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 672/672 [00:28<00:00, 23.44q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/training/bm25-b=0.75-k_1=1.2\".\n",
      "Done. run file is stored under \"grid-search/training/bm25-b=0.75-k_1=1.2/run.txt\".\n",
      "Run bm25-b=0.75-k_1=1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 672/672 [00:28<00:00, 23.89q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/training/bm25-b=0.75-k_1=1.3\".\n",
      "Done. run file is stored under \"grid-search/training/bm25-b=0.75-k_1=1.3/run.txt\".\n",
      "Run bm25-b=0.8-k_1=1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 672/672 [00:27<00:00, 24.07q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/training/bm25-b=0.8-k_1=1.1\".\n",
      "Done. run file is stored under \"grid-search/training/bm25-b=0.8-k_1=1.1/run.txt\".\n",
      "Run bm25-b=0.8-k_1=1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 672/672 [00:34<00:00, 19.61q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/training/bm25-b=0.8-k_1=1.2\".\n",
      "Done. run file is stored under \"grid-search/training/bm25-b=0.8-k_1=1.2/run.txt\".\n",
      "Run bm25-b=0.8-k_1=1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 672/672 [00:33<00:00, 20.00q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/training/bm25-b=0.8-k_1=1.3\".\n",
      "Done. run file is stored under \"grid-search/training/bm25-b=0.8-k_1=1.3/run.txt\".\n"
     ]
    }
   ],
   "source": [
    "run_bm25_grid_search_run(index_LemurKrovetz, 'grid-search/training', pt_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The download is derived from The LongEval Dataset under the \"Qwant LongEval Attribution-NonCommercial-ShareAlike License\". Hence, the download is also under this License. By using it, you agree to the terms of this license. Please find details at: https://lindat.mff.cuni.cz/repository/xmlui/page/Qwant_LongEval_BY-NC-SA_License\n",
      "Download from Zenodo: https://zenodo.org/records/10628882/files/validation-20231104-truth.zip?download=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 100%|██████████| 479k/479k [00:00<00:00, 4.39MiB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /root/.tira/extracted_datasets/ir-lab-jena-leipzig-wise-2023/validation-20231104-training/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_val = ir_datasets.load(validation_dataset)\n",
    "queries_val = pt.io.read_topics(ir_datasets.topics_file(validation_dataset), format='trecxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run bm25-b=0.7-k_1=1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 882/882 [00:43<00:00, 20.17q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/validation/bm25-b=0.7-k_1=1.1\".\n",
      "Done. run file is stored under \"grid-search/validation/bm25-b=0.7-k_1=1.1/run.txt\".\n",
      "Run bm25-b=0.7-k_1=1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 882/882 [00:45<00:00, 19.49q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/validation/bm25-b=0.7-k_1=1.2\".\n",
      "Done. run file is stored under \"grid-search/validation/bm25-b=0.7-k_1=1.2/run.txt\".\n",
      "Run bm25-b=0.7-k_1=1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 882/882 [00:44<00:00, 19.67q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/validation/bm25-b=0.7-k_1=1.3\".\n",
      "Done. run file is stored under \"grid-search/validation/bm25-b=0.7-k_1=1.3/run.txt\".\n",
      "Run bm25-b=0.75-k_1=1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 882/882 [00:44<00:00, 19.64q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/validation/bm25-b=0.75-k_1=1.1\".\n",
      "Done. run file is stored under \"grid-search/validation/bm25-b=0.75-k_1=1.1/run.txt\".\n",
      "Run bm25-b=0.75-k_1=1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 882/882 [00:44<00:00, 19.81q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/validation/bm25-b=0.75-k_1=1.2\".\n",
      "Done. run file is stored under \"grid-search/validation/bm25-b=0.75-k_1=1.2/run.txt\".\n",
      "Run bm25-b=0.75-k_1=1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 882/882 [00:47<00:00, 18.50q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/validation/bm25-b=0.75-k_1=1.3\".\n",
      "Done. run file is stored under \"grid-search/validation/bm25-b=0.75-k_1=1.3/run.txt\".\n",
      "Run bm25-b=0.8-k_1=1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 882/882 [00:48<00:00, 18.34q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/validation/bm25-b=0.8-k_1=1.1\".\n",
      "Done. run file is stored under \"grid-search/validation/bm25-b=0.8-k_1=1.1/run.txt\".\n",
      "Run bm25-b=0.8-k_1=1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 882/882 [00:48<00:00, 18.34q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/validation/bm25-b=0.8-k_1=1.2\".\n",
      "Done. run file is stored under \"grid-search/validation/bm25-b=0.8-k_1=1.2/run.txt\".\n",
      "Run bm25-b=0.8-k_1=1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 882/882 [00:52<00:00, 16.82q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"grid-search/validation/bm25-b=0.8-k_1=1.3\".\n",
      "Done. run file is stored under \"grid-search/validation/bm25-b=0.8-k_1=1.3/run.txt\".\n"
     ]
    }
   ],
   "source": [
    "run_bm25_grid_search_run(index_LemurKrovetz, 'grid-search/validation', queries_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tira in /usr/local/lib/python3.10/dist-packages (0.0.139)\n",
      "Collecting trectools\n",
      "  Downloading trectools-0.0.50.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-terrier in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
      "Requirement already satisfied: numpy==1.* in /usr/local/lib/python3.10/dist-packages (from tira) (1.26.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tira) (23.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tira) (2.1.3)\n",
      "Requirement already satisfied: requests==2.*,>=2.26 in /usr/local/lib/python3.10/dist-packages (from tira) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tira) (4.66.1)\n",
      "Requirement already satisfied: docker==7.*,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from tira) (7.1.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker==7.*,>=7.1.0->tira) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.*,>=2.26->tira) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.*,>=2.26->tira) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.*,>=2.26->tira) (3.6)\n",
      "Collecting bs4>=0.0.0.1\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from trectools) (4.9.3)\n",
      "Collecting matplotlib>=1.5\n",
      "  Downloading matplotlib-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting sarge>=0.1.1\n",
      "  Downloading sarge-0.1.7.post1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.15 in /usr/local/lib/python3.10/dist-packages (from trectools) (1.3.2)\n",
      "Requirement already satisfied: scipy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from trectools) (1.11.4)\n",
      "Requirement already satisfied: ir-datasets>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.5.5)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.14.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.3.2)\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.3.3)\n",
      "Requirement already satisfied: chest in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.2.3)\n",
      "Requirement already satisfied: matchpy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.5.5)\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (3.1.2)\n",
      "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (from python-terrier) (3.2)\n",
      "Requirement already satisfied: nptyping==1.4.4 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.4.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.3.7)\n",
      "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.2.14)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from python-terrier) (10.1.0)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.5.6)\n",
      "Requirement already satisfied: typish>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4>=0.0.0.1->trectools) (4.12.2)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (3.2.3)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.2)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (2.6)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (2.3.2)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\n",
      "Requirement already satisfied: lz4>=3.1.10 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (4.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (6.0.1)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.6)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.12)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /usr/local/lib/python3.10/dist-packages (from ir-measures>=0.3.1->python-terrier) (1.0.12)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow>=8\n",
      "  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 KB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.55.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 KB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->trectools) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tira) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tira) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.15->trectools) (3.2.0)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.10/dist-packages (from chest->python-terrier) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->python-terrier) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->python-terrier) (2.1.3)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from matchpy->python-terrier) (2.1.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->python-terrier) (0.5.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4>=0.0.0.1->trectools) (2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->python-terrier) (1.16.0)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\n",
      "Building wheels for collected packages: trectools\n",
      "  Building wheel for trectools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for trectools: filename=trectools-0.0.50-py3-none-any.whl size=28599 sha256=b6587bfcdaa1f4e5b1aff5b552a5d6aca21ba505de8b078f6c5a474c1a0a3951\n",
      "  Stored in directory: /root/.cache/pip/wheels/48/f7/1d/79a8e3f8fa6e794cd08f9a14df11eb6ce933416febcdd1e612\n",
      "Successfully built trectools\n",
      "Installing collected packages: sarge, pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, bs4, trectools\n",
      "Successfully installed bs4-0.0.2 contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.2 kiwisolver-1.4.7 matplotlib-3.9.3 pillow-11.0.0 pyparsing-3.2.0 sarge-0.1.7.post1 trectools-0.0.50\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install tira trectools python-terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trectools import TrecRun, TrecQrel, TrecEval\n",
    "from tira.rest_api_client import Client\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "tira = Client()\n",
    "\n",
    "def load_qrels(dataset):\n",
    "    return TrecQrel(tira.download_dataset('ir-lab-jena-leipzig-wise-2023', dataset, truth_dataset=True) + '/qrels.txt')\n",
    "\n",
    "training_qrels = load_qrels('training-20231104-training')\n",
    "validation_qrels = load_qrels('validation-20231104-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_run(run_dir, qrels):\n",
    "    run = TrecRun(run_dir + '/run.txt')\n",
    "    trec_eval = TrecEval(run, qrels)\n",
    "\n",
    "    return {\n",
    "        'run': run.get_runid(),\n",
    "        'nDCG@10': trec_eval.get_ndcg(depth=10),\n",
    "        'nDCG@10 (unjudgedRemoved)': trec_eval.get_ndcg(depth=10, removeUnjudged=True),\n",
    "        'MAP': trec_eval.get_map(depth=10),\n",
    "        'MRR': trec_eval.get_reciprocal_rank()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>nDCG@10 (unjudgedRemoved)</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MRR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bm25-b=0.75-k_1=1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bm25-b=0.75-k_1=1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bm25-b=0.8-k_1=1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bm25-b=0.7-k_1=1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bm25-b=0.8-k_1=1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bm25-b=0.7-k_1=1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bm25-b=0.8-k_1=1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bm25-b=0.75-k_1=1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bm25-b=0.7-k_1=1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   run  nDCG@10  nDCG@10 (unjudgedRemoved)  MAP  MRR\n",
       "0  bm25-b=0.75-k_1=1.3  0.0      0.0                        0.0  0.0\n",
       "1  bm25-b=0.75-k_1=1.2  0.0      0.0                        0.0  0.0\n",
       "2  bm25-b=0.8-k_1=1.1   0.0      0.0                        0.0  0.0\n",
       "3  bm25-b=0.7-k_1=1.3   0.0      0.0                        0.0  0.0\n",
       "4  bm25-b=0.8-k_1=1.2   0.0      0.0                        0.0  0.0\n",
       "5  bm25-b=0.7-k_1=1.2   0.0      0.0                        0.0  0.0\n",
       "6  bm25-b=0.8-k_1=1.3   0.0      0.0                        0.0  0.0\n",
       "7  bm25-b=0.75-k_1=1.1  0.0      0.0                        0.0  0.0\n",
       "8  bm25-b=0.7-k_1=1.1   0.0      0.0                        0.0  0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = []\n",
    "for r in glob('grid-search/training/bm25*'):\n",
    "    df += [evaluate_run(r, training_qrels)]\n",
    "df = pd.DataFrame(df)\n",
    "df.sort_values('nDCG@10', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:311: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>nDCG@10 (unjudgedRemoved)</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MRR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bm25-b=0.75-k_1=1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bm25-b=0.75-k_1=1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bm25-b=0.8-k_1=1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bm25-b=0.7-k_1=1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bm25-b=0.8-k_1=1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bm25-b=0.7-k_1=1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bm25-b=0.8-k_1=1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bm25-b=0.75-k_1=1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bm25-b=0.7-k_1=1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   run  nDCG@10  nDCG@10 (unjudgedRemoved)  MAP  MRR\n",
       "0  bm25-b=0.75-k_1=1.3  0.0      0.0                        0.0  0.0\n",
       "1  bm25-b=0.75-k_1=1.2  0.0      0.0                        0.0  0.0\n",
       "2  bm25-b=0.8-k_1=1.1   0.0      0.0                        0.0  0.0\n",
       "3  bm25-b=0.7-k_1=1.3   0.0      0.0                        0.0  0.0\n",
       "4  bm25-b=0.8-k_1=1.2   0.0      0.0                        0.0  0.0\n",
       "5  bm25-b=0.7-k_1=1.2   0.0      0.0                        0.0  0.0\n",
       "6  bm25-b=0.8-k_1=1.3   0.0      0.0                        0.0  0.0\n",
       "7  bm25-b=0.75-k_1=1.1  0.0      0.0                        0.0  0.0\n",
       "8  bm25-b=0.7-k_1=1.1   0.0      0.0                        0.0  0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = []\n",
    "for r in glob('grid-search/validation/bm25*'):\n",
    "    df += [evaluate_run(r, validation_qrels)]\n",
    "df = pd.DataFrame(df)\n",
    "df.sort_values('nDCG@10', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create the run\n",
    "In the next steps, we would like to apply our retrieval system to some topics, to prepare a 'run' file, containing the retrieved documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's have a short look at the first three topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1030303</td>\n",
       "      <td>who is aziz hashim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1037496</td>\n",
       "      <td>who is rep scalise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1043135</td>\n",
       "      <td>who killed nicholas ii of russia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid                             query\n",
       "0  1030303  who is aziz hashim              \n",
       "1  1037496  who is rep scalise              \n",
       "2  1043135  who killed nicholas ii of russia"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The `'text'` argument below selects the topics `text` field as the query.\n",
    "pt_dataset.get_topics('text').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, retrieve results for all the topics (may take a while):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = bm25_lemurkrovetz(pt_dataset.get_topics('text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for the retrieval. Here are the first 10 entries of the run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1030303</td>\n",
       "      <td>53852</td>\n",
       "      <td>8726436</td>\n",
       "      <td>0</td>\n",
       "      <td>31.681671</td>\n",
       "      <td>who is aziz hashim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1030303</td>\n",
       "      <td>56041</td>\n",
       "      <td>8726433</td>\n",
       "      <td>1</td>\n",
       "      <td>25.966276</td>\n",
       "      <td>who is aziz hashim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1030303</td>\n",
       "      <td>62116</td>\n",
       "      <td>8726435</td>\n",
       "      <td>2</td>\n",
       "      <td>23.863442</td>\n",
       "      <td>who is aziz hashim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1030303</td>\n",
       "      <td>32183</td>\n",
       "      <td>8726429</td>\n",
       "      <td>3</td>\n",
       "      <td>23.391821</td>\n",
       "      <td>who is aziz hashim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1030303</td>\n",
       "      <td>35867</td>\n",
       "      <td>8726437</td>\n",
       "      <td>4</td>\n",
       "      <td>21.030669</td>\n",
       "      <td>who is aziz hashim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1030303</td>\n",
       "      <td>17637</td>\n",
       "      <td>8726430</td>\n",
       "      <td>5</td>\n",
       "      <td>19.967200</td>\n",
       "      <td>who is aziz hashim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1030303</td>\n",
       "      <td>42957</td>\n",
       "      <td>7156982</td>\n",
       "      <td>6</td>\n",
       "      <td>19.967200</td>\n",
       "      <td>who is aziz hashim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1030303</td>\n",
       "      <td>21803</td>\n",
       "      <td>8726434</td>\n",
       "      <td>7</td>\n",
       "      <td>19.474804</td>\n",
       "      <td>who is aziz hashim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1030303</td>\n",
       "      <td>59828</td>\n",
       "      <td>1305520</td>\n",
       "      <td>8</td>\n",
       "      <td>17.849161</td>\n",
       "      <td>who is aziz hashim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1030303</td>\n",
       "      <td>60002</td>\n",
       "      <td>3302257</td>\n",
       "      <td>9</td>\n",
       "      <td>17.832781</td>\n",
       "      <td>who is aziz hashim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid  docid    docno  rank      score               query\n",
       "0  1030303  53852  8726436  0     31.681671  who is aziz hashim\n",
       "1  1030303  56041  8726433  1     25.966276  who is aziz hashim\n",
       "2  1030303  62116  8726435  2     23.863442  who is aziz hashim\n",
       "3  1030303  32183  8726429  3     23.391821  who is aziz hashim\n",
       "4  1030303  35867  8726437  4     21.030669  who is aziz hashim\n",
       "5  1030303  17637  8726430  5     19.967200  who is aziz hashim\n",
       "6  1030303  42957  7156982  6     19.967200  who is aziz hashim\n",
       "7  1030303  21803  8726434  7     19.474804  who is aziz hashim\n",
       "8  1030303  59828  1305520  8     17.849161  who is aziz hashim\n",
       "9  1030303  60002  3302257  9     17.832781  who is aziz hashim"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Persist and upload run to TIRA\n",
    "\n",
    "The output of our retrieval system is a run file. This run file can later (and, e.g., in a different notebook or by a different person) be statistically evaluated. We will therefore first upload the run to TIRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../data/runs\".\n",
      "Done. run file is stored under \"../data/runs/run.txt.gz\".\n",
      "Run uploaded to TIRA. Claim ownership via: https://www.tira.io/claim-submission/f3476d3b-6066-434b-8df1-1bc77b9fdfd7\n"
     ]
    }
   ],
   "source": [
    "from tira.third_party_integrations import persist_and_normalize_run\n",
    "\n",
    "persist_and_normalize_run(\n",
    "    run,\n",
    "    # Give your approach a short but descriptive name tag.\n",
    "    system_name='bm25-modifiedStemmer', \n",
    "    default_output='../data/runs',\n",
    "    upload_to_tira=pt_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on the link in the cell output above to claim your submission on TIRA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Improve\n",
    "\n",
    "Building your own index can be already one way that you can try to improve upon this baseline (if you want to focus on creating good document representations). Other ways could include reformulating queries or tuning parameters or building better retrieval pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25 with Porter Stemmer</td>\n",
       "      <td>0.489469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25 with no Stemmer</td>\n",
       "      <td>0.468890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BM25 with Snowball Stemmer</td>\n",
       "      <td>0.489216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BM25 with LemurKrovetz Stemmer</td>\n",
       "      <td>0.490341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BM25 with Standford Lemmatizer</td>\n",
       "      <td>0.482512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name  ndcg_cut_10\n",
       "0  BM25 with Porter Stemmer        0.489469   \n",
       "1  BM25 with no Stemmer            0.468890   \n",
       "2  BM25 with Snowball Stemmer      0.489216   \n",
       "3  BM25 with LemurKrovetz Stemmer  0.490341   \n",
       "4  BM25 with Standford Lemmatizer  0.482512   "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier import Experiment \n",
    "\n",
    "Experiment(\n",
    "    [bm25_porter, bm25_none, bm25_snowball, bm25_lemurkrovetz, bm25_standfordLemmatizer],\n",
    "    topics = pt_dataset.get_topics(\"text\"),\n",
    "    qrels = pt_dataset.get_qrels(),\n",
    "    eval_metrics=[\"ndcg_cut_10\"],\n",
    "    names=[\"BM25 with Porter Stemmer\", \"BM25 with no Stemmer\", \"BM25 with Snowball Stemmer\", \"BM25 with LemurKrovetz Stemmer\", \"BM25 with Standford Lemmatizer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19335</td>\n",
       "      <td>1082489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19335</td>\n",
       "      <td>109063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19335</td>\n",
       "      <td>1231806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19335</td>\n",
       "      <td>1324075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19335</td>\n",
       "      <td>1509459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>1136962</td>\n",
       "      <td>8336581</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>1136962</td>\n",
       "      <td>8380913</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>1136962</td>\n",
       "      <td>8537921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>1136962</td>\n",
       "      <td>937258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>1136962</td>\n",
       "      <td>999215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12976 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           qid    docno  label iteration\n",
       "0        19335  1082489      0         0\n",
       "1        19335   109063      0         0\n",
       "2        19335  1231806      0         0\n",
       "3        19335  1324075      0         0\n",
       "4        19335  1509459      0         0\n",
       "...        ...      ...    ...       ...\n",
       "12971  1136962  8336581      0         0\n",
       "12972  1136962  8380913      0         0\n",
       "12973  1136962  8537921      0         0\n",
       "12974  1136962   937258      1         0\n",
       "12975  1136962   999215      0         0\n",
       "\n",
       "[12976 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_dataset.get_qrels()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
